{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Ij6VC-jnnRP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn import Flatten,Linear,ReLU, Conv2d,MaxPool2d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset=datasets.MNIST('mnist_dataset',train=True,download=True,transform=transforms.ToTensor())\n",
        "train_loader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "IiEXJJzSojJZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=torch.nn.Sequential(Conv2d(in_channels=1,out_channels=6,kernel_size=3,stride=1,padding=1),\n",
        "                          ReLU(),\n",
        "                          MaxPool2d(2,2),\n",
        "                          Conv2d(in_channels=6,out_channels=6,kernel_size=3,stride=1,padding=1),\n",
        "                          ReLU(),\n",
        "                          Flatten(),\n",
        "                          Linear(6*14*14,10)\n",
        "                          )\n",
        "model=model.cuda()\n",
        "\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "wVvg0Vq2sdKW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_every=100\n",
        "for epoch in range(5):\n",
        "  print('Epoch: ',epoch)\n",
        "  totalLoss=0\n",
        "  totalExamples=0\n",
        "  totalCorrect=0\n",
        "\n",
        "  for iterations, (X,y) in enumerate(train_loader):\n",
        "    X=X.cuda()\n",
        "    y=y.cuda()\n",
        "\n",
        "    scores=model(X)\n",
        "\n",
        "    loss=torch.nn.functional.cross_entropy(scores,y)\n",
        "\n",
        "    preds=torch.argmax(scores,dim=1)\n",
        "    correct=torch.sum(preds==y)\n",
        "\n",
        "    totalLoss+=loss.item()\n",
        "    totalCorrect+=correct.item()\n",
        "    totalExamples+=len(X)\n",
        "    if iterations % print_every==0:\n",
        "      print('loss=',totalLoss/totalExamples,'correct=',totalCorrect/totalExamples)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIJdZniDusVh",
        "outputId": "a1659159-6459-44d3-e62d-a466052ce93e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "loss= 0.00010290172212990001 correct= 1.0\n",
            "loss= 0.0004645615715189436 correct= 0.9918007425742574\n",
            "loss= 0.000516260056270649 correct= 0.9897388059701493\n",
            "loss= 0.0005045514555719133 correct= 0.9902927740863787\n",
            "loss= 0.0005207065312520841 correct= 0.9898301122194514\n",
            "loss= 0.0005298421534596586 correct= 0.9897392714570858\n",
            "loss= 0.0005358611817334203 correct= 0.9894446755407654\n",
            "loss= 0.0005626745868995125 correct= 0.9891449714693296\n",
            "loss= 0.0005594930091873938 correct= 0.9891541822721598\n",
            "loss= 0.0005601156039509454 correct= 0.9891613485016648\n",
            "Epoch:  1\n",
            "loss= 0.0002605376939754933 correct= 1.0\n",
            "loss= 0.0005340893000207546 correct= 0.9887066831683168\n",
            "loss= 0.0005223515442562689 correct= 0.9895055970149254\n",
            "loss= 0.000485991094841744 correct= 0.9899294019933554\n",
            "loss= 0.0005073158439123821 correct= 0.9894404613466334\n",
            "loss= 0.0005104563830670401 correct= 0.9896768962075848\n",
            "loss= 0.0005135713543740668 correct= 0.9895486688851913\n",
            "loss= 0.0005154701124302093 correct= 0.9896130527817404\n",
            "loss= 0.0005315602142236434 correct= 0.9893102372034956\n",
            "loss= 0.0005309319674175907 correct= 0.9891786903440621\n",
            "Epoch:  2\n",
            "loss= 5.8026209444506094e-05 correct= 1.0\n",
            "loss= 0.00045375168723478396 correct= 0.9916460396039604\n",
            "loss= 0.0005152032662096386 correct= 0.9909825870646766\n",
            "loss= 0.0004693611144890788 correct= 0.9913309800664452\n",
            "loss= 0.0004895466177786465 correct= 0.9905314837905237\n",
            "loss= 0.0005026432650383269 correct= 0.9899887724550899\n",
            "loss= 0.0004885910603251509 correct= 0.9901726289517471\n",
            "loss= 0.00048352528425913907 correct= 0.9902817403708987\n",
            "loss= 0.0004956611290301621 correct= 0.9901295255930087\n",
            "loss= 0.0004871595617020793 correct= 0.9903752774694784\n",
            "Epoch:  3\n",
            "loss= 0.0006416739779524505 correct= 0.984375\n",
            "loss= 0.0004357388610839221 correct= 0.9919554455445545\n",
            "loss= 0.00040981205854417505 correct= 0.9919154228855721\n",
            "loss= 0.0004263593733454865 correct= 0.9919019933554817\n",
            "loss= 0.00041251898674861767 correct= 0.991622506234414\n",
            "loss= 0.00043640461263565525 correct= 0.9909244011976048\n",
            "loss= 0.00044691591135964393 correct= 0.9908485856905158\n",
            "loss= 0.00045204104066158134 correct= 0.9908166904422254\n",
            "loss= 0.00045947552966078934 correct= 0.9906757178526842\n",
            "loss= 0.0004559324680999387 correct= 0.990774139844617\n",
            "Epoch:  4\n",
            "loss= 0.00016575348854530603 correct= 1.0\n",
            "loss= 0.00044157770263956254 correct= 0.9935024752475248\n",
            "loss= 0.0004382208536679091 correct= 0.992304104477612\n",
            "loss= 0.00040359857715268173 correct= 0.9923691860465116\n",
            "loss= 0.0004279847568020279 correct= 0.9915056109725686\n",
            "loss= 0.00042571952140051306 correct= 0.9916417165668663\n",
            "loss= 0.00044267558752484525 correct= 0.9915245424292846\n",
            "loss= 0.0004220823975233459 correct= 0.9916859843081313\n",
            "loss= 0.0004273371569155309 correct= 0.9915730337078652\n",
            "loss= 0.0004300976563326741 correct= 0.9915545227524972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = datasets.MNIST('mnist_dataset', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "8NgUx4Oi2mKt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct=0\n",
        "with torch.no_grad():\n",
        "  for X,y in test_loader:\n",
        "    X = X.cuda()\n",
        "    y = y.cuda()\n",
        "\n",
        "    scores = model(X)\n",
        "    preds = torch.argmax(scores, dim=1)\n",
        "\n",
        "    correct+=torch.sum(preds==y)\n",
        "  print(correct.item()/len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMBtkjhB3uB8",
        "outputId": "a257db52-c74e-4d5e-9bf9-8b99a7effa6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9857\n"
          ]
        }
      ]
    }
  ]
}